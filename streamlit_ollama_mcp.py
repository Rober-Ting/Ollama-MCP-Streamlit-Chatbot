import streamlit as st
import asyncio
from mcpclient_manager import MCPClientManager, get_available_servers, load_config, initialize_agent_and_tools
from ollama_toolmanager import OllamaToolManager
from ollama_agent import OllamaAgent
import ollama
from model_setting import sync_model_tool_support, get_model_tool_support, set_model_tool_support

# å¾ streamlit_manager è®€å–èŠå¤©å€å¡Šé«˜åº¦
from streamlit_manager import get_chat_container_height, get_stream_mode
CHAT_CONTAINER_HEIGHT = get_chat_container_height()

async def summarize_tool_result(agent, tool_result, user_prompt):
    """
    å°‡å·¥å…·å›æ‡‰ä¸Ÿçµ¦ LLMï¼Œè«‹ LLM å¹«å¿™ç¸½çµ/èªªæ˜ã€‚
    """
    summary_prompt = (
        f"ä½¿ç”¨è€…åŸå§‹å•é¡Œï¼š{user_prompt}\n"
        f"å·¥å…·å›æ‡‰å¦‚ä¸‹ï¼š\n{tool_result}\n"
        "è«‹ç”¨è‡ªç„¶èªè¨€ç¸½çµé€™å€‹å·¥å…·å›æ‡‰ï¼Œè‹¥æœ‰éŒ¯èª¤è«‹å‹å–„èªªæ˜åŸå› ä¸¦çµ¦å‡ºå»ºè­°ã€‚"
    )
    async for chunk in agent.get_response(summary_prompt, stream=False):
        return chunk

try:
    # åˆå§‹åŒ– session state
    if "agent" not in st.session_state:
        st.session_state.agent = None
    if "mcpclient" not in st.session_state:
        st.session_state.mcpclient = None
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    if "connected" not in st.session_state:
        st.session_state.connected = False
    if "selected_model" not in st.session_state:
        st.session_state.selected_model = None
    if "selected_server" not in st.session_state:
        st.session_state.selected_server = None
    if "page" not in st.session_state:
        st.session_state.page = "chat"
    if "selected_mcp_server" not in st.session_state:
        st.session_state.selected_mcp_server = None
    if "processing" not in st.session_state:
        st.session_state.processing = False

    # Sidebar: é¸æ¨¡å‹ã€server
    # å…¨å±€ sidebar æŒ‰éˆ•å­—é«”è®Šå¤§
    st.markdown(
        """
        <style>
        section[data-testid="stSidebar"] button {
            font-size: 1.2em !important;
            font-weight: bold !important;
        }
        </style>
        """,
        unsafe_allow_html=True
    )
    st.sidebar.title("ğŸ¦™Ollama MCP Client Setting")
    # å–å¾—æœ¬åœ°æ¨¡å‹æ¸…å–®
    try:
        available_models_data = ollama.list()
        available_models = [model['model'] for model in available_models_data['models']]
    except Exception as e:
        available_models = []
        st.sidebar.error(f"å–å¾—æ¨¡å‹å¤±æ•—: {e}")

    # åŒæ­¥æ¨¡å‹æ”¯æ´ç‹€æ…‹
    model_tool_support_dict = sync_model_tool_support(available_models)

    prev_model = st.session_state.get("_prev_selected_model")
    prev_server = st.session_state.get("_prev_selected_server")
    selected_model = st.sidebar.selectbox("Ollama model selection", available_models, key="selected_model")
    servers = get_available_servers()
    selected_server = st.sidebar.selectbox("MCP Server selection", servers, key="selected_server")
    # è‹¥æ¨¡å‹æˆ– server æœ‰è®Šå‹•ï¼Œæ¸…é™¤ agent/mcpclient/connected
    if (prev_model is not None and prev_model != selected_model) or (prev_server is not None and prev_server != selected_server):
        st.session_state.agent = None
        st.session_state.mcpclient = None
        st.session_state.connected = False
        st.session_state.chat_history = []
    st.session_state["_prev_selected_model"] = selected_model
    st.session_state["_prev_selected_server"] = selected_server
    model_supports_tool = get_model_tool_support(selected_model)

    if st.sidebar.button("connect/initialize"):
        try:
            agent = initialize_agent_and_tools(selected_model, selected_server, None)
            st.session_state.agent = agent  # åªå­˜ agentï¼ˆç„¡ async contextï¼‰
            st.session_state.connected = True
            st.session_state.chat_history = []
            st.sidebar.success("connected!")
        except Exception as e:
            import traceback
            st.session_state.connected = False
            st.session_state.agent = None
            st.sidebar.error(f"âŒ MCP server é€£ç·šå¤±æ•—ï¼Œè«‹ç¢ºèª server æ˜¯å¦å·²å•Ÿå‹•ã€‚\nè©³ç´°éŒ¯èª¤: {e}")
            st.sidebar.text(traceback.format_exc())
            

    # æ–°å¢ MCP Server ç®¡ç†æŒ‰éˆ•
    st.sidebar.markdown("---")
    if st.sidebar.button("ğŸ› ï¸ MCP Server management"):
        st.session_state.page = "mcp_server"
        st.rerun()
    # æ–°å¢ èŠå¤©å®¤ åˆ‡æ›æŒ‰éˆ•
    if st.sidebar.button("ğŸ’¬ Chat room"):
        st.session_state.page = "chat"
        st.rerun()

    # MCP Server management page
    if st.session_state.get("page") == "mcp_server":
        st.title("ğŸ› ï¸ MCP Server management")
        servers = get_available_servers()
        for key in servers:
            if st.button(key, key=key):
                st.session_state.selected_mcp_server = key
                st.session_state.page = "mcp_tools"
                st.rerun()
        st.stop()

    # MCP Tools é é¢
    if st.session_state.get("page") == "mcp_tools":
        server_type = st.session_state.get("selected_mcp_server")
        st.title(f"ğŸ”§ MCP Tools @ {server_type}")
        import asyncio
        from mcpclient_manager import MCPClientManager
        async def show_tools():
            try:
                async with MCPClientManager(server_type) as mcpclient:
                    tools = await mcpclient.get_available_tools()
                    if not tools:
                        st.info("æ­¤ MCP Server ç„¡å¯ç”¨å·¥å…·ã€‚")
                        return
                    tab_labels = [getattr(tool, 'name', str(tool)) for tool in tools]
                    tabs = st.tabs(tab_labels)
                    for i, tool in enumerate(tools):
                        with tabs[i]:
                            st.subheader("ğŸ“ åŠŸèƒ½æè¿°")
                            st.write(getattr(tool, 'description', ''))
                            st.subheader("ğŸ› ï¸ Input åƒæ•¸")
                            st.json(getattr(tool, 'inputSchema', {}))
                            st.subheader("ğŸ“¤ Return å…§å®¹")
                            output_schema = getattr(tool, 'outputSchema', None)
                            if output_schema:
                                st.json(output_schema)
                            else:
                                st.info("ç„¡ outputSchema å®šç¾©")
            except Exception as e:
                st.error(f"é€£ç·š MCP Server å¤±æ•—: {e}")
        asyncio.run(show_tools())
        st.stop()

    # ä¸»ç•«é¢
    st.title(" Ollama MCP Client")
    if not st.session_state.connected:
        st.info("Please select the model and MCP server on the left, and click connect/initialize")
        st.stop()

    # é¡¯ç¤ºç›®å‰ç‹€æ…‹ï¼ˆç¾åŒ–ç‰ˆï¼‰
    col1, col2 = st.columns([1, 1])
    with col1:
        st.markdown("#### ğŸ¦™ ç›®å‰æ¨¡å‹")
        st.markdown(f"<span style='font-size:1.2em;font-weight:bold'>{selected_model}</span>", unsafe_allow_html=True)
        if not model_supports_tool:
            st.markdown("<span style='color:red;font-weight:bold'>âŒ <b>ç„¡æ³•ä½¿ç”¨ MCP å·¥å…·</b></span>", unsafe_allow_html=True)
        else:
            st.markdown("<span style='color:green;font-weight:bold'>âœ… å¯ä½¿ç”¨ MCP å·¥å…·</span>", unsafe_allow_html=True)
    with col2:
        st.markdown("#### ğŸ› ï¸ MCP Server")
        st.markdown(f"<span style='font-size:1.2em;font-weight:bold'>{selected_server}</span>", unsafe_allow_html=True)

    

    # å…©å€‹åˆ†é ï¼šå³æ™‚èŠå¤©ã€æ­·å²ç´€éŒ„
    tab1, tab2 = st.tabs(["ğŸ’¬ å³æ™‚èŠå¤©", "ğŸ•‘ æ­·å²ç´€éŒ„"])

    with tab1:
        chat_container = st.container(height=CHAT_CONTAINER_HEIGHT)
        with chat_container:
            for idx, chat in enumerate(st.session_state.chat_history):
                # è·³éæœ€å¾Œä¸€å‰‡ç©ºçš„ assistantï¼Œè®“ streaming éšæ®µä¾†é¡¯ç¤º
                if idx == len(st.session_state.chat_history) - 1 and chat["role"] == "assistant" and chat["content"] == "":
                    continue
                with st.chat_message(chat["role"]):
                    if chat["role"] == "user":
                        st.write(chat["content"])
                    else:
                        # assistant å›æ‡‰ï¼Œæ”¯æ´å·¥å…·å‘¼å«é¡¯ç¤º
                        if isinstance(chat["content"], dict):
                            tool_call = chat["content"].get("tool_call")
                            tool_result = chat["content"].get("tool_result")
                            final_response = chat["content"].get("final_response")
                            if tool_call:
                                st.markdown(f"ğŸ¤– **æ¨¡å‹æ±ºå®šå‘¼å«å·¥å…·**ï¼š`{tool_call}`")
                            if tool_result:
                                if "å·¥å…·åŸ·è¡Œå¤±æ•—" in tool_result or "error" in tool_result.lower():
                                    st.error(tool_result)
                                else:
                                    st.markdown(f"ğŸ› ï¸ **å·¥å…·å›æ‡‰**ï¼š`{tool_result}`")
                            if final_response:
                                st.markdown(f"**æœ€çµ‚å›æ‡‰**ï¼š{final_response}")
                        else:
                            st.write(str(chat["content"]))
        # è¼¸å…¥æ¡†
        col1, col2 = st.columns([6, 1])
        with col1:
            prompt = st.chat_input("è«‹è¼¸å…¥ä½ çš„å•é¡Œï¼š", disabled=st.session_state.get("processing", False))
        with col2:
            if st.button("æ¸…é™¤", help="æ¸…é™¤å³æ™‚èŠå¤©ä¸¦å­˜å…¥æ­·å²ç´€éŒ„"):
                if "chat_history_archive" not in st.session_state:
                    st.session_state.chat_history_archive = []
                st.session_state.chat_history_archive.extend(st.session_state.chat_history)
                st.session_state.chat_history = []
                st.rerun()
        if prompt and st.session_state.agent:
            st.session_state.chat_history.append({"role": "user", "content": prompt})
            st.session_state.chat_history.append({"role": "assistant", "content": ""})
            st.session_state["processing"] = True  # æ¨™è¨˜æ­£åœ¨è™•ç†
            st.rerun()  # å…ˆ rerun è®“ user è¨Šæ¯å³æ™‚é¡¯ç¤º
        # assistant streaming
        if (
            len(st.session_state.chat_history) >= 2 and
            st.session_state.chat_history[-1]["role"] == "assistant" and
            st.session_state.chat_history[-1]["content"] == "" and
            st.session_state.get("processing", False)  # åªæœ‰åœ¨è™•ç†ä¸­æ‰åŸ·è¡Œ
        ):
            with st.status("Processing...", expanded=True):
                import asyncio
                stream_mode = get_stream_mode()
                if stream_mode:
                    with chat_container.chat_message("assistant"):
                        ai_placeholder = st.empty()
                        def update(content):
                            st.session_state.chat_history[-1]["content"] = content
                            ai_placeholder.markdown(content)
                        async def stream_agent_response():
                            async for chunk in st.session_state.agent.get_response(st.session_state.chat_history[-2]["content"], stream=True):
                                if isinstance(chunk, dict) and chunk.get("tool_result"):
                                    summary = await summarize_tool_result(
                                        st.session_state.agent,
                                        chunk["tool_result"],
                                        st.session_state.chat_history[-2]["content"]
                                    )
                                    
                                    update(summary)
                                    break
                                else:
                                    update(chunk)
                        asyncio.run(stream_agent_response())
                else:
                    async def get_first_response():
                        agen = st.session_state.agent.get_response(st.session_state.chat_history[-2]["content"], stream=False)
                        async for chunk in agen:
                            if isinstance(chunk, dict) and chunk.get("tool_result"):
                                summary = await summarize_tool_result(
                                    st.session_state.agent,
                                    chunk["tool_result"],
                                    st.session_state.chat_history[-2]["content"]
                                )
                                return summary
                            else:
                                return chunk
                    res = asyncio.run(get_first_response())
                    st.session_state.chat_history[-1]["content"] = res
            st.session_state["processing"] = False  # æ¸…é™¤è™•ç†æ¨™è¨˜
            st.rerun()

    with tab2:
        chat_container2 = st.container(height=CHAT_CONTAINER_HEIGHT)
        with chat_container2:
            for chat in st.session_state.get("chat_history_archive", []):
                with st.chat_message(chat["role"]):
                    st.write(chat["content"])
        if st.button("æ¸…é™¤æ­·å²ç´€éŒ„"):
            st.session_state["chat_history_archive"] = []
            st.rerun()
except Exception as e:
    st.error(f"æ‡‰ç”¨ç¨‹åºéŒ¯èª¤: {str(e)}")
    import traceback
    st.exception(e)
    st.stop() 